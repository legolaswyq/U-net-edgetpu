{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization,Activation, MaxPool2D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import re\n",
    "import os \n",
    "import glob \n",
    "import random\n",
    "import logging\n",
    "from tensorflow.keras import backend as K\n",
    "import math\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", use_bias=False)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(input, num_filters):\n",
    "    x = conv_block(input, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "\n",
    "def decoder_block(input, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_unet(input_shape, n_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    c1, p1 = encoder_block(inputs, 16)\n",
    "    c2, p2 = encoder_block(p1, 32)\n",
    "    c3, p3 = encoder_block(p2, 64)\n",
    "    c4, p4 = encoder_block(p3, 128)\n",
    "\n",
    "    c5 = conv_block(p4, 256) #Bridge\n",
    "    c6 = decoder_block(c5, c4, 128)\n",
    "    c7 = decoder_block(c6, c3, 64)\n",
    "    c8 = decoder_block(c7, c2, 32)\n",
    "    c9 = decoder_block(c8, c1, 16)\n",
    "\n",
    "    if n_classes == 1:  #Binary\n",
    "        activation = 'sigmoid'\n",
    "    else:\n",
    "        activation = 'softmax'\n",
    "    \n",
    "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(c9)\n",
    "    model = Model(inputs, outputs, name=\"U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/app/seg/models/v5_finetune.h5\"\n",
    "model = build_unet(input_shape=(128,128,3), n_classes=1)\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representative dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    dataset_dir = \"/app/seg/data/images/train\"\n",
    "    files = glob.glob(dataset_dir + \"/*.jpg\")\n",
    "    for file in files:\n",
    "        img = tf.io.read_file(file)\n",
    "        img = tf.image.decode_image(img, channels=3, dtype=tf.float32)\n",
    "        resize_img = tf.image.resize_with_pad(img, target_height=128, target_width=128, method='bilinear')\n",
    "        input_img = tf.expand_dims(resize_img, axis=0)\n",
    "        yield [input_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input.set_shape((1,) + model.input.shape[1:])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "save_path = \"/app/seg/models/v5_finetune.tflite\"\n",
    "\n",
    "with open(save_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edgetpu compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge TPU Compiler version 16.0.384591198\n",
      "Started a compilation timeout timer of 180 seconds.\n",
      "\n",
      "Model compiled successfully in 652 ms.\n",
      "\n",
      "Input model: models/v5_finetune.tflite\n",
      "Input size: 1.92MiB\n",
      "Output model: v5_finetune_edgetpu.tflite\n",
      "Output size: 1.98MiB\n",
      "On-chip memory used for caching model parameters: 1.96MiB\n",
      "On-chip memory remaining for caching model parameters: 4.73MiB\n",
      "Off-chip memory used for streaming uncached model parameters: 3.75KiB\n",
      "Number of Edge TPU subgraphs: 1\n",
      "Total number of operations: 45\n",
      "Operation log: v5_finetune_edgetpu.log\n",
      "See the operation log file for individual operation details.\n",
      "Compilation child process completed within timeout period.\n",
      "Compilation succeeded! \n"
     ]
    }
   ],
   "source": [
    "!edgetpu_compiler models/v5_finetune.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
